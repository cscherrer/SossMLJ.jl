<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Multinomial logistic regression Â· SossMLJ.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">SossMLJ.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../example-linear-regression/">Linear regression</a></li><li class="is-active"><a class="tocitem" href>Multinomial logistic regression</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Multinomial logistic regression</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Multinomial logistic regression</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/cscherrer/SossMLJ.jl/blob/master/examples/example-multinomial-logistic-regression.jl" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Multinomial-logistic-regression"><a class="docs-heading-anchor" href="#Multinomial-logistic-regression">Multinomial logistic regression</a><a id="Multinomial-logistic-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Multinomial-logistic-regression" title="Permalink"></a></h1><p>Import the necessary packages:</p><pre><code class="language-julia">using DataFrames
using Distributions
using MLJBase
using NNlib
using RDatasets
using Soss
using SossMLJ
using Statistics</code></pre><p>In this example, we fit a Bayesian multinomial logistic regression model with the canonical link function.</p><p>Suppose that we are given a matrix of features <code>X</code> and a column vector of labels <code>y</code>. <code>X</code> has <code>n</code> rows and <code>p</code> columns. <code>y</code> has <code>n</code> elements. We assume that our observation vector <code>y</code> is a realization of a random variable <code>Y</code>. We define <code>Î¼</code> (mu) as the expected value of <code>Y</code>, i.e. <code>Î¼ := E[Y]</code>. Our model comprises three components:</p><ol><li>The probability distribution of <code>Y</code>. We assume that each <code>Yáµ¢</code> follows a multinomial distribution with <code>k</code> categories, mean <code>Î¼áµ¢</code>, and one trial.</li><li>The systematic component, which consists of linear predictor <code>Î·</code> (eta), which we define as <code>Î· := XÎ²</code>, where <code>Î²</code> is the column vector of <code>p</code> coefficients.</li><li>The link function <code>g</code>, which provides the following relationship: <code>g(E[Y]) = g(Î¼) = Î· = XÎ²</code>. It follows that <code>Î¼ = gâ»Â¹(Î·)</code>, where <code>gâ»Â¹</code> denotes the inverse of <code>g</code>. In multinomial logistic regression, the canonical link function is the generalized logit function. The inverse of the generalized logit function is the softmax function. Therefore, when using the canonical link function, <code>Î¼ = gâ»Â¹(Î·) = softmax(Î·)</code>.</li></ol><p>A multinomial distribution with one trial is equivalent to the categorical distribution. Therefore, the following two statements are equivalent:</p><ul><li><code>Yáµ¢</code> follows a multinomial distribution with <code>k</code> categories, mean <code>Î¼áµ¢</code>, and one trial.</li><li><code>Yáµ¢</code> follows a categorical distribution with <code>k</code> categories and mean <code>Î¼áµ¢</code>.</li></ul><p>Observe that the logistic regression model is a special case of the multinomial logistic regression model where <code>k = 2</code>.</p><p>In this model, the parameters that we want to estimate are the coefficients <code>Î²</code>. We need to select prior distributions for these parameters. For each <code>Î²áµ¢</code> we choose a normal distribution with zero mean and unit variance. Here, <code>Î²áµ¢</code> denotes the <code>i</code>th component of <code>Î²</code>.</p><p>We define this model using the Soss probabilistic programming library:</p><pre><code class="language-julia">m = @model X,pool begin
    n = size(X, 1) # number of observations
    p = size(X, 2) # number of features
    k = length(pool.levels) # number of classes
    Î² ~ Normal(0.0, 1.0) |&gt; iid(p, k) # coefficients
    Î· = X * Î² # linear predictor
    Î¼ = NNlib.softmax(Î·; dims=2) # Î¼ = gâ»Â¹(Î·) = softmax(Î·)
    y_dists = UnivariateFinite(pool.levels, Î¼; pool=pool) # `UnivariateFinite` is mathematically equivalent to `Categorical`
    y ~ For(j -&gt; y_dists[j], n) # `Yáµ¢ ~ UnivariateFinite(mean=Î¼áµ¢, categories=k)`, which is mathematically equivalent to `Yáµ¢ ~ Categorical(mean=Î¼áµ¢, categories=k)`
end;</code></pre><p>Import the <em>Iris</em> flower data set:</p><pre><code class="language-julia">iris = dataset(&quot;datasets&quot;, &quot;iris&quot;);</code></pre><p>Define our feature columns:</p><pre><code class="language-julia">feature_columns = [
    :PetalLength,
    :PetalWidth,
    :SepalLength,
    :SepalWidth,
]</code></pre><pre class="documenter-example-output">4-element Array{Symbol,1}:
 :PetalLength
 :PetalWidth
 :SepalLength
 :SepalWidth</pre><p>Define our label column:</p><pre><code class="language-julia">label_column = :Species</code></pre><pre class="documenter-example-output">:Species</pre><p>Convert the Soss model into a <code>SossMLJModel</code>:</p><pre><code class="language-julia">model = SossMLJModel(;
    model       = m,
    predictor   = MLJBase.UnivariateFinite,
    hyperparams = (pool=iris.Species.pool,),
    infer       = dynamicHMC,
    response    = :y,
);</code></pre><p>Create an MLJ machine for fitting our model:</p><pre><code class="language-julia">mach = MLJBase.machine(model, iris[!, feature_columns], iris[!, :Species])</code></pre><pre class="documenter-example-output">[34mMachine{SossMLJModel{,â€¦}} @959[39m trained 0 times.
  args: 
    1:	[34mSource @860[39m â `ScientificTypes.Table{AbstractArray{ScientificTypes.Continuous,1}}`
    2:	[34mSource @420[39m â `AbstractArray{ScientificTypes.Multiclass{3},1}`
</pre><p>Fit the machine. This may take several minutes.</p><pre><code class="language-julia">MLJBase.fit!(mach)</code></pre><pre class="documenter-example-output">[34mMachine{SossMLJModel{,â€¦}} @959[39m trained 1 time.
  args: 
    1:	[34mSource @860[39m â `ScientificTypes.Table{AbstractArray{ScientificTypes.Continuous,1}}`
    2:	[34mSource @420[39m â `AbstractArray{ScientificTypes.Multiclass{3},1}`
</pre><p>Construct the joint posterior:</p><pre><code class="language-julia">predictor_joint = MLJBase.predict_joint(mach, iris[!, feature_columns])
typeof(predictor_joint)</code></pre><pre class="documenter-example-output">SossMLJ.SossMLJPredictor{SossMLJModel{MLJBase.UnivariateFinite,Model{NamedTuple{(:X, :pool),T} where T&lt;:Tuple,TypeEncoding(begin
    k = length(pool.levels)
    p = size(X, 2)
    Î² ~ Normal(0.0, 1.0) |&gt; iid(p, k)
    Î· = X * Î²
    Î¼ = NNlib.softmax(Î·; dims = 2)
    y_dists = UnivariateFinite(pool.levels, Î¼; pool = pool)
    n = size(X, 1)
    y ~ For((j-&gt;begin
                    y_dists[j]
                end), n)
end),TypeEncoding(Main.ex-example-multinomial-logistic-regression)},NamedTuple{(:pool,),Tuple{CategoricalArrays.CategoricalPool{String,UInt8,CategoricalArrays.CategoricalValue{String,UInt8}}}},typeof(dynamicHMC),Symbol,typeof(SossMLJ.default_transform)},Array{NamedTuple{(:Î²,),Tuple{Array{Float64,2}}},1},Model{NamedTuple{(:X, :pool, :Î²),T} where T&lt;:Tuple,TypeEncoding(begin
    Î· = X * Î²
    Î¼ = NNlib.softmax(Î·; dims = 2)
    y_dists = UnivariateFinite(pool.levels, Î¼; pool = pool)
    n = size(X, 1)
    y ~ For((j-&gt;begin
                    y_dists[j]
                end), n)
end),TypeEncoding(Main.ex-example-multinomial-logistic-regression)},NamedTuple{(:X, :pool),Tuple{Array{Float64,2},CategoricalArrays.CategoricalPool{String,UInt8,CategoricalArrays.CategoricalValue{String,UInt8}}}}}</pre><p>Draw a single sample from the joint posterior:</p><pre><code class="language-julia">single_sample = rand(predictor_joint)</code></pre><pre class="documenter-example-output">150-element Array{CategoricalArrays.CategoricalValue{String,UInt8},1}:
 &quot;setosa&quot;
 &quot;setosa&quot;
 &quot;setosa&quot;
 &quot;setosa&quot;
 &quot;setosa&quot;
 &quot;setosa&quot;
 &quot;setosa&quot;
 &quot;setosa&quot;
 &quot;setosa&quot;
 &quot;setosa&quot;
 â‹®
 &quot;virginica&quot;
 &quot;virginica&quot;
 &quot;virginica&quot;
 &quot;virginica&quot;
 &quot;virginica&quot;
 &quot;virginica&quot;
 &quot;virginica&quot;
 &quot;versicolor&quot;
 &quot;virginica&quot;</pre><p>For each row in the dataset, construct the marginal posterior predictive distribution</p><pre><code class="language-julia">predictor_marginal = MLJBase.predict(mach, iris[!, feature_columns])</code></pre><pre class="documenter-example-output">150-element MLJBase.UnivariateFiniteArray{ScientificTypes.Multiclass{3},String,UInt8,Float64,1}:
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.982, versicolor=&gt;0.018, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.955, versicolor=&gt;0.0446, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.969, versicolor=&gt;0.0308, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.951, versicolor=&gt;0.0486, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.985, versicolor=&gt;0.0148, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.981, versicolor=&gt;0.0194, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.973, versicolor=&gt;0.0268, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.973, versicolor=&gt;0.027, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.94, versicolor=&gt;0.0598, virginica=&gt;0.0)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.947, versicolor=&gt;0.0526, virginica=&gt;0.0)
 â‹®
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.003, versicolor=&gt;0.29, virginica=&gt;0.707)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.0002, versicolor=&gt;0.073, virginica=&gt;0.927)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.0, versicolor=&gt;0.0604, virginica=&gt;0.94)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.0004, versicolor=&gt;0.0514, virginica=&gt;0.948)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.001, versicolor=&gt;0.159, virginica=&gt;0.84)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.0002, versicolor=&gt;0.175, virginica=&gt;0.825)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.0012, versicolor=&gt;0.237, virginica=&gt;0.762)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.0006, versicolor=&gt;0.0774, virginica=&gt;0.922)
 UnivariateFinite{ScientificTypes.Multiclass{3}}(setosa=&gt;0.0004, versicolor=&gt;0.187, virginica=&gt;0.813)</pre><p>predictor_marginal is a <code>UnivariateFiniteVector</code></p><pre><code class="language-julia">typeof(predictor_marginal)</code></pre><pre class="documenter-example-output">MLJBase.UnivariateFiniteArray{ScientificTypes.Multiclass{3},String,UInt8,Float64,1}</pre><p><code>predictor_marginal</code> has one element for each row in the data set</p><pre><code class="language-julia">@show size(predictor_marginal); @show size(iris, 1);</code></pre><pre class="documenter-example-output">size(predictor_marginal) = (150,)
size(iris, 1) = 150</pre><p>Use cross-validation to evaluate the model with respect to the Brier score:</p><pre><code class="language-julia">evaluate!(mach, resampling=CV(; nfolds = 4, shuffle = true), measure=brier_score, operation=MLJBase.predict)</code></pre><pre class="documenter-example-output">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _.measure                            â”‚ _.measurement â”‚ _.per_fold                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BrierScore{MLJBase.UnivariateFinite} â”‚ -0.0901       â”‚ [-0.1, -0.106, -0.068, -0.0866] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
_.per_observation = [[[-0.0164, -0.00011, ..., -0.0119], [-0.00102, -0.00933, ..., -0.259], [-0.0602, -0.000184, ..., -0.0238], [-0.00283, -0.0358, ..., -0.0855]]]
_.fitted_params_per_fold = [ â€¦ ]
_.report_per_fold = [ â€¦ ]
</pre><p>Use cross-validation to evaluate the model with respect to accuracy:</p><pre><code class="language-julia">evaluate!(mach, resampling=CV(; nfolds = 4, shuffle = true), measure=accuracy, operation=MLJBase.predict_mode)</code></pre><pre class="documenter-example-output">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _.measure â”‚ _.measurement â”‚ _.per_fold                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ accuracy  â”‚ 0.96          â”‚ [0.974, 0.947, 0.973, 0.946] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
_.per_observation = [missing]
_.fitted_params_per_fold = [ â€¦ ]
_.report_per_fold = [ â€¦ ]
</pre><p>The cross-validated accuracy is greater than 90%, which is pretty good!</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../example-linear-regression/">Â« Linear regression</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 4 September 2020 19:15">Friday 4 September 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
