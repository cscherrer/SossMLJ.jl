<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Linear regression Â· SossMLJ.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">SossMLJ.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>Linear regression</a></li><li><a class="tocitem" href="../example-multinomial-logistic-regression/">Multinomial logistic regression</a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Linear regression</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Linear regression</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/cscherrer/SossMLJ.jl/blob/master/examples/example-linear-regression.jl" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Linear-regression"><a class="docs-heading-anchor" href="#Linear-regression">Linear regression</a><a id="Linear-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-regression" title="Permalink"></a></h1><p>Import the necessary packages:</p><pre><code class="language-julia">using Distributions
using MLJBase
using Soss
using SossMLJ
using Statistics</code></pre><p>In this example, we fit a Bayesian linear regression model with the canonical link function.</p><p>Suppose that we are given a matrix of features <code>X</code> and a column vector of labels <code>y</code>. <code>X</code> has <code>n</code> rows and <code>p</code> columns. <code>y</code> has <code>n</code> elements. We assume that our observation vector <code>y</code> is a realization of a random variable <code>Y</code>. We define <code>Î¼</code> (mu) as the expected value of <code>Y</code>, i.e. <code>Î¼ := E[Y]</code>. Our model comprises three components:</p><ol><li>The probability distribution of <code>Y</code>: for linear regression, we assume that each <code>Yáµ¢</code> follows a normal distribution with mean <code>Î¼áµ¢</code> and variance <code>ÏƒÂ²</code>.</li><li>The systematic component, which consists of linear predictor <code>Î·</code> (eta), which we define as <code>Î· := XÎ²</code>, where <code>Î²</code> is the column vector of <code>p</code> coefficients.</li><li>The link function <code>g</code>, which provides the following relationship: <code>g(E[Y]) = g(Î¼) = Î· = XÎ²</code>. It follows that <code>Î¼ = gâ»Â¹(Î·)</code>, where <code>gâ»Â¹</code> denotes the inverse of <code>g</code>. For linear regression, the canonical link function is the identity function. Therefore, when using the canonical link function, <code>Î¼ = gâ»Â¹(Î·) = Î·</code>.</li></ol><p>In this model, the parameters that we want to estimate are <code>Î²</code> and <code>Ïƒ</code>. We need to select prior distributions for these parameters. For each <code>Î²áµ¢</code> we choose a normal distribution with zero mean and variance <code>sÂ²</code>. Here, <code>Î²áµ¢</code> denotes the <code>i</code>th component of <code>Î²</code>. For <code>Ïƒ</code>, we will choose a half-normal distribution with variance <code>tÂ²</code>. <code>s</code> and <code>t</code> are hyperparameters that we will need to choose.</p><p>We define this model using the Soss probabilistic programming library:</p><pre><code class="language-julia">m = @model X, s, t begin
    p = size(X, 2) # number of features
    Î² ~ Normal(0, s) |&gt; iid(p) # coefficients
    Ïƒ ~ HalfNormal(t) # dispersion
    Î· = X * Î² # linear predictor
    Î¼ = Î· # `Î¼ = gâ»Â¹(Î·) = Î·``
    y ~ For(eachindex(Î¼)) do j
        Normal(Î¼[j], Ïƒ) # `Yáµ¢ ~ Normal(mean=Î¼áµ¢, variance=ÏƒÂ²)`
    end
end;</code></pre><p>Generate some synthetic features. Let us generate two continuous features and two binary categorical features.</p><pre><code class="language-julia">num_rows = 100
x1 = randn(num_rows)
x2 = randn(num_rows)
x3 = Int.(rand(num_rows) .&gt; 0.5)
x4 = Int.(rand(num_rows) .&gt; 0.5)
X = (x1 = x1, x2 = x2, x3 = x3, x4 = x4)</code></pre><pre class="documenter-example-output">(x1 = [0.23117038086047362, -0.2830476493288421, 0.07531777415855226, 1.0692795145326788, 0.450930884301871, 0.17592321062280683, 0.48278014245041323, -0.2517378860148917, -0.09597797791363531, 2.549253671088458  â€¦  0.47451452549224404, 1.198479086058487, 0.9622987451860825, -0.6980245833101895, -0.38804069428149834, 0.2530024295347078, -0.5254463777430619, -0.291082000565828, -0.29619869982344665, 2.2472864526215433],
 x2 = [-1.1010937758404047, 1.234745867024765, 0.4247225997062604, 0.4086648078005086, 0.799972112975795, 0.2579997871626222, 2.1613746566791963, -1.0957964629038894, -0.8642136474271954, 0.6347108848841875  â€¦  0.31681211498244594, 1.6478818288248522, 0.0972670059912407, 0.2978556085916699, 0.8612284200900224, 0.3338003202162013, -0.15846192844199875, 0.6047342445741245, -0.12530516315970663, -2.069946144850977],
 x3 = [0, 0, 1, 0, 0, 0, 0, 1, 1, 1  â€¦  1, 0, 1, 0, 1, 1, 0, 0, 1, 0],
 x4 = [1, 1, 0, 1, 0, 0, 0, 0, 1, 1  â€¦  1, 0, 0, 0, 0, 1, 1, 1, 1, 0],)</pre><p>Define the hyperparameters of our prior distributions:</p><pre><code class="language-julia">hyperparams = (s=0.1, t=0.1)</code></pre><pre class="documenter-example-output">(s = 0.1,
 t = 0.1,)</pre><p>Convert the Soss model into a <code>SossMLJModel</code>:</p><pre><code class="language-julia">model = SossMLJModel(m;
    hyperparams = hyperparams,
    transform   = X -&gt; (X=matrix(X),),
    infer       = dynamicHMC,
    response    = :y,
);</code></pre><p>Generate some synthetic labels:</p><pre><code class="language-julia">args = merge(model.transform(X), hyperparams)
truth = rand(m(args))</code></pre><pre class="documenter-example-output">(p = 4,
 Î· = [-0.06630244778293429, 0.004750437896366935, 0.03144867001953064, -0.22389767339457137, -0.08469463019080983, -0.032617036204774436, -0.10093252538446937, 0.10026721660446307, 0.03660281578303788, -0.43512715294417315  â€¦  -0.07187592339521542, -0.22134142511706842, -0.12020467134894662, 0.11903051544766331, 0.10858604879945608, -0.03349323448068927, 0.0578483501370556, 0.011099038107484693, 0.06560943286925865, -0.3744861583733037],
 Î¼ = [-0.06630244778293429, 0.004750437896366935, 0.03144867001953064, -0.22389767339457137, -0.08469463019080983, -0.032617036204774436, -0.10093252538446937, 0.10026721660446307, 0.03660281578303788, -0.43512715294417315  â€¦  -0.07187592339521542, -0.22134142511706842, -0.12020467134894662, 0.11903051544766331, 0.10858604879945608, -0.03349323448068927, 0.0578483501370556, 0.011099038107484693, 0.06560943286925865, -0.3744861583733037],
 Ïƒ = 0.049745662666630996,
 Î² = [-0.17387857827006248, -0.007859535386740052, 0.04788293981062494, -0.03476095611610316],
 y = [-0.09705018327463337, 0.04440725714301154, -0.05755059628937813, -0.1872481336878324, -0.09166710065252497, -0.08392210029932926, -0.20790208599053955, 0.12296300262833976, 0.06825048819970822, -0.4343593692222299  â€¦  -0.04257020320512586, -0.24034385611633358, -0.17794386162280995, 0.13005774617910476, 0.0726946758940981, -0.0012775243519325408, 0.09150521970014405, -0.06755723016573231, 0.02477774210196653, -0.3310883100474672],)</pre><p>Create an MLJ machine for fitting our model:</p><pre><code class="language-julia">mach = MLJBase.machine(model, X, truth.y)</code></pre><pre class="documenter-example-output">[34mMachine{SossMLJModel{Model{,â€¦},â€¦}} @584[39m trained 0 times.
  args: 
    1:	[34mSource @185[39m â `ScientificTypes.Table{Union{AbstractArray{ScientificTypes.Continuous,1}, AbstractArray{ScientificTypes.Count,1}}}`
    2:	[34mSource @327[39m â `AbstractArray{ScientificTypes.Continuous,1}`
</pre><p>Fit the machine. This may take several minutes.</p><pre><code class="language-julia">fit!(mach)</code></pre><pre class="documenter-example-output">[34mMachine{SossMLJModel{Model{,â€¦},â€¦}} @584[39m trained 1 time.
  args: 
    1:	[34mSource @185[39m â `ScientificTypes.Table{Union{AbstractArray{ScientificTypes.Continuous,1}, AbstractArray{ScientificTypes.Count,1}}}`
    2:	[34mSource @327[39m â `AbstractArray{ScientificTypes.Continuous,1}`
</pre><p>Construct the posterior distribution and the joint posterior predictive distribution:</p><pre><code class="language-julia">predictor_joint = predict_joint(mach, X)
typeof(predictor_joint)</code></pre><pre class="documenter-example-output">SossMLJ.SossMLJPredictor{SossMLJModel{Soss.Model{NamedTuple{(:X, :s, :t),T} where T&lt;:Tuple,TypeEncoding(begin
    Ïƒ ~ HalfNormal(t)
    p = size(X, 2)
    Î² ~ Normal(0, s) |&gt; iid(p)
    Î· = X * Î²
    Î¼ = Î·
    y ~ For(eachindex(Î¼)) do j
            Normal(Î¼[j], Ïƒ)
        end
end),TypeEncoding(Main.ex-example-linear-regression)},Main.ex-example-linear-regression.var&quot;#1#2&quot;,typeof(Soss.dynamicHMC),NamedTuple{(:s, :t),Tuple{Float64,Float64}},Symbol},Array{NamedTuple{(:Ïƒ, :Î²),Tuple{Float64,Array{Float64,1}}},1},Soss.Model{NamedTuple{(:X, :Ïƒ, :Î²),T} where T&lt;:Tuple,TypeEncoding(begin
    Î· = X * Î²
    Î¼ = Î·
    y ~ For(eachindex(Î¼)) do j
            Normal(Î¼[j], Ïƒ)
        end
end),TypeEncoding(Main.ex-example-linear-regression)},NamedTuple{(:X, :s, :t),Tuple{Array{Float64,2},Float64,Float64}}}</pre><p>Draw a single sample from the joint posterior predictive distribution:</p><pre><code class="language-julia">single_sample = rand(predictor_joint; response = :y)</code></pre><pre class="documenter-example-output">100-element Array{Float64,1}:
  0.013217919044694201
  0.0974345572850803
  0.03308189248060496
 -0.23117753200045255
 -0.0878578319402316
 -0.13056563377167418
 -0.07230503735137454
  0.07684432554536948
  0.10428876520362944
 -0.40762492829284297
  â‹®
 -0.1991048341072281
 -0.17259292771268905
  0.18055510382850132
  0.034548730940027625
  0.13744618176727053
  0.058763380019780084
 -0.04829020108101066
  0.06354849539475398
 -0.34709355117729745</pre><p>Evaluate the logpdf of the joint posterior predictive distribution at this sample:</p><pre><code class="language-julia">logpdf(predictor_joint, single_sample)</code></pre><pre class="documenter-example-output">152.8197120019455</pre><p>True <code>Î²</code>:</p><pre><code class="language-julia">truth.Î²</code></pre><pre class="documenter-example-output">4-element Array{Float64,1}:
 -0.17387857827006248
 -0.007859535386740052
  0.04788293981062494
 -0.03476095611610316</pre><p>Posterior distribution of <code>Î²</code></p><pre><code class="language-julia">predict_particles(mach, X; response = :Î²)</code></pre><pre class="documenter-example-output">4-element Array{MonteCarloMeasurements.Particles{Float64,1000},1}:
 -0.174 Â± 0.0044
 -0.0115 Â± 0.0048
  0.0515 Â± 0.007
 -0.0305 Â± 0.0078</pre><p>Difference between the posterior distribution of <code>Î²</code> to the true values:</p><pre><code class="language-julia">truth.Î² - predict_particles(mach, X; response = :Î²)</code></pre><pre class="documenter-example-output">4-element Array{MonteCarloMeasurements.Particles{Float64,1000},1}:
  0.000399 Â± 0.0044
  0.00362 Â± 0.0048
 -0.00357 Â± 0.007
 -0.00422 Â± 0.0078</pre><p>Compare the joint posterior predictive distribution of <code>Î¼</code> to the true values:</p><pre><code class="language-julia">truth.Î¼ - predict_particles(mach, X; response = :Î¼)</code></pre><pre class="documenter-example-output">100-element Array{MonteCarloMeasurements.Particles{Float64,1000},1}:
 -0.00811 Â± 0.0086
  0.000139 Â± 0.011
 -0.002 Â± 0.0072
 -0.00231 Â± 0.01
  0.00307 Â± 0.0044
  0.001 Â± 0.0015
  0.00801 Â± 0.011
 -0.00763 Â± 0.0092
 -0.011 Â± 0.0074
 -0.00447 Â± 0.014
  â‹®
  0.00644 Â± 0.0098
 -0.00283 Â± 0.0076
  0.000799 Â± 0.0033
 -0.000607 Â± 0.0083
 -0.00648 Â± 0.0075
 -0.005 Â± 0.0076
 -0.00214 Â± 0.0087
 -0.00836 Â± 0.0069
 -0.00659 Â± 0.013</pre><p>Compare the joint posterior predictive distribution of <code>y</code> to the true values:</p><pre><code class="language-julia">truth.y - predict_particles(mach, X; response = :y)</code></pre><pre class="documenter-example-output">100-element Array{MonteCarloMeasurements.Particles{Float64,1000},1}:
 -0.0387 Â± 0.046
  0.0398 Â± 0.047
 -0.091 Â± 0.046
  0.0343 Â± 0.047
 -0.00389 Â± 0.046
 -0.0503 Â± 0.045
 -0.099 Â± 0.047
  0.0152 Â± 0.046
  0.0207 Â± 0.046
 -0.00369 Â± 0.048
  â‹®
 -0.0126 Â± 0.046
 -0.0606 Â± 0.046
  0.0117 Â± 0.046
 -0.0364 Â± 0.046
  0.0258 Â± 0.046
  0.0289 Â± 0.046
 -0.0809 Â± 0.046
 -0.0491 Â± 0.046
  0.0369 Â± 0.047</pre><p>Construct each of the marginal posterior predictive distributions:</p><pre><code class="language-julia">predictor_marginal = MLJBase.predict(mach, X)
typeof(predictor_marginal)</code></pre><pre class="documenter-example-output">Array{SossMLJ.SossMLJPredictor{SossMLJModel{Soss.Model{NamedTuple{(:X, :s, :t),T} where T&lt;:Tuple,TypeEncoding(begin
    Ïƒ ~ HalfNormal(t)
    p = size(X, 2)
    Î² ~ Normal(0, s) |&gt; iid(p)
    Î· = X * Î²
    Î¼ = Î·
    y ~ For(eachindex(Î¼)) do j
            Normal(Î¼[j], Ïƒ)
        end
end),TypeEncoding(Main.ex-example-linear-regression)},Main.ex-example-linear-regression.var&quot;#1#2&quot;,typeof(Soss.dynamicHMC),NamedTuple{(:s, :t),Tuple{Float64,Float64}},Symbol},Array{NamedTuple{(:Ïƒ, :Î²),Tuple{Float64,Array{Float64,1}}},1},Soss.Model{NamedTuple{(:X, :Ïƒ, :Î²),T} where T&lt;:Tuple,TypeEncoding(begin
    Î· = X * Î²
    Î¼ = Î·
    y ~ For(eachindex(Î¼)) do j
            Normal(Î¼[j], Ïƒ)
        end
end),TypeEncoding(Main.ex-example-linear-regression)},NamedTuple{(:X, :s, :t),Tuple{Array{Float64,2},Float64,Float64}}},1}</pre><p><code>predictor_marginal</code> has one element for each row in <code>X</code></p><pre><code class="language-julia">size(predictor_marginal)</code></pre><pre class="documenter-example-output">(100,)</pre><p>Draw a single sample from each of the marginal posterior predictive distributions:</p><pre><code class="language-julia">only.(rand.(predictor_marginal))</code></pre><pre class="documenter-example-output">100-element Array{Float64,1}:
 -0.05473289175379736
 -0.03216109980295069
  0.04476044910824546
 -0.30757791364462134
 -0.09505703359735442
 -0.08706446940701779
 -0.11782493892777306
  0.07333323202390157
 -0.03193945634386411
 -0.4251522290822447
  â‹®
 -0.1787905467607025
 -0.11209630008391012
  0.06507064497755835
  0.10900353636100223
  0.0520385663887212
  0.1368438091177177
  0.04296808851740086
  0.08209846986030359
 -0.4152825539654259</pre><p>Use cross-validation to evaluate the model with respect to the expected value of the root mean square error (RMSE)</p><pre><code class="language-julia">evaluate!(mach, resampling=CV(), measure=rms_expected, operation=predict_particles)</code></pre><pre class="documenter-example-output">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _.measure   â”‚ _.measurement â”‚ _.per_fold                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RMSExpected â”‚ 0.0641        â”‚ [0.0637, 0.0623, 0.0595, 0.0622, 0.0725, 0.0645] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
_.per_observation = [missing]
</pre><p>Use cross-validation to evaluate the model with respect to the median of the root mean square error (RMSE)</p><pre><code class="language-julia">evaluate!(mach, resampling=CV(), measure=rms_median, operation=predict_particles)</code></pre><pre class="documenter-example-output">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _.measure â”‚ _.measurement â”‚ _.per_fold                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RMSMedian â”‚ 0.0639        â”‚ [0.0631, 0.0621, 0.0592, 0.0618, 0.0725, 0.0645] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
_.per_observation = [missing]
</pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">Â« Home</a><a class="docs-footer-nextpage" href="../example-multinomial-logistic-regression/">Multinomial logistic regression Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 27 August 2020 06:22">Thursday 27 August 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
