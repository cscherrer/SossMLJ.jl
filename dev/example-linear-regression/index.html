<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Linear regression ¬∑ SossMLJ.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">SossMLJ.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>Linear regression</a></li><li><a class="tocitem" href="../example-multinomial-logistic-regression/">Multinomial logistic regression</a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Linear regression</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Linear regression</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/cscherrer/SossMLJ.jl/blob/master/examples/example-linear-regression.jl" title="Edit on GitHub"><span class="docs-icon fab">ÔÇõ</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Linear-regression"><a class="docs-heading-anchor" href="#Linear-regression">Linear regression</a><a id="Linear-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-regression" title="Permalink"></a></h1><p>Import the necessary packages:</p><pre><code class="language-julia">using Distributions
using MLJBase
using Soss
using SossMLJ
using Statistics</code></pre><p>In this example, we fit a Bayesian linear regression model with the canonical link function.</p><p>Suppose that we are given a matrix of features <code>X</code> and a column vector of labels <code>y</code>. <code>X</code> has <code>n</code> rows and <code>p</code> columns. <code>y</code> has <code>n</code> elements. We assume that our observation vector <code>y</code> is a realization of a random variable <code>Y</code>. We define <code>Œº</code> (mu) as the expected value of <code>Y</code>, i.e. <code>Œº := E[Y]</code>. Our model comprises three components:</p><ol><li>The probability distribution of <code>Y</code>: for linear regression, we assume that</li></ol><p>each <code>Y·µ¢</code> follows a normal distribution with mean <code>Œº·µ¢</code> and variance <code>œÉ¬≤</code>.</p><ol><li>The systematic component, which consists of linear predictor <code>Œ∑</code> (eta),</li></ol><p>which we define as <code>Œ∑ := XŒ≤</code>, where <code>Œ≤</code> is the column vector of <code>p</code> coefficients.</p><ol><li>The link function <code>g</code>, which provides the following relationship:</li></ol><p><code>g(E[Y]) = g(Œº) = Œ∑ = XŒ≤</code>. It follows that <code>Œº = g‚Åª¬π(Œ∑)</code>, where <code>g‚Åª¬π</code> denotes the inverse of <code>g</code>. For linear regression, the canonical link function is the identity function. Therefore, when using the canonical link function, <code>Œº = g‚Åª¬π(Œ∑) = Œ∑</code>.</p><p>In this model, the parameters that we want to estimate are <code>Œ≤</code> and <code>œÉ</code>. We need to select prior distributions for these parameters. For each <code>Œ≤·µ¢</code> we choose a normal distribution with zero mean and variance <code>s¬≤</code>. Here, <code>Œ≤·µ¢</code> denotes the <code>i</code>th component of <code>Œ≤</code>. For <code>œÉ</code>, we will choose a half-normal distribution with variance <code>t¬≤</code>. <code>s</code> and <code>t</code> are hyperparameters that we will need to choose.</p><p>We define this model using the Soss probabilistic programming library:</p><pre><code class="language-julia">m = @model X, s, t begin
    p = size(X, 2) # number of features
    Œ≤ ~ Normal(0, s) |&gt; iid(p) # coefficients
    œÉ ~ HalfNormal(t) # dispersion
    Œ∑ = X * Œ≤ # linear predictor
    Œº = Œ∑ # `Œº = g‚Åª¬π(Œ∑) = Œ∑``
    y ~ For(eachindex(Œº)) do j
        Normal(Œº[j], œÉ) # `Y·µ¢ ~ Normal(mean=Œº·µ¢, variance=œÉ¬≤)`
    end
end;</code></pre><p>Generate some synthetic features. Let us generate two continuous features and two binary categorical features.</p><pre><code class="language-julia">num_rows = 100
x1 = randn(num_rows)
x2 = randn(num_rows)
x3 = Int.(rand(num_rows) .&gt; 0.5)
x4 = Int.(rand(num_rows) .&gt; 0.5)
X = (x1 = x1, x2 = x2, x3 = x3, x4 = x4)</code></pre><pre class="documenter-example-output">(x1 = [1.9481679666604161, -1.3609601089554015, -0.874834583166804, -2.453604597262034, 0.6645084260266182, -0.2391712478518784, -2.516612794887434, -0.6232072647282665, 1.2627374886701273, 0.029703726425369725  ‚Ä¶  -1.0109704950496468, 0.5852133934626993, -0.19832250252306288, -0.4777649157361417, 0.35101957235905934, 1.8230160665309851, -0.007836126342370742, -2.743875978479315, -1.1625475159173584, 0.8588849652170403],
 x2 = [-1.927266432196009, 2.9281153346395183, 1.206213826792075, -0.9811193878435579, -0.30059268746843826, -0.12843602409078894, 1.5725352577675404, 0.10601504134071911, 0.525296348965856, -1.764098721261949  ‚Ä¶  -1.2038908126673673, 0.10409319908055582, 0.5497945460419953, -1.335382117554405, -0.4089868858408731, -0.4339180150089241, -0.4272414014009688, -0.2243004578831901, -2.0799677977531577, 0.546390857382444],
 x3 = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1  ‚Ä¶  1, 1, 0, 1, 0, 0, 0, 1, 0, 1],
 x4 = [0, 0, 0, 1, 1, 1, 1, 1, 0, 1  ‚Ä¶  1, 1, 0, 0, 0, 1, 1, 1, 1, 0],)</pre><p>Define the hyperparameters of our prior distributions:</p><pre><code class="language-julia">hyperparams = (s=0.1, t=0.1)</code></pre><pre class="documenter-example-output">(s = 0.1,
 t = 0.1,)</pre><p>Convert the Soss model into a <code>SossMLJModel</code>:</p><pre><code class="language-julia">model = SossMLJModel(m;
    hyperparams = hyperparams,
    transform   = X -&gt; (X=matrix(X),),
    infer       = dynamicHMC,
    response    = :y,
);</code></pre><p>Generate some synthetic labels:</p><pre><code class="language-julia">args = merge(model.transform(X), hyperparams)
truth = rand(m(args))</code></pre><pre class="documenter-example-output">(p = 4,
 Œ∑ = [-0.07425253786441717, 0.06260598855694459, 0.035656016260655655, 0.17147415210953537, 0.07818205464771197, 0.10772637696733235, 0.1907825647786839, 0.12137636804604132, -0.0340565694970403, 0.0902126436118248  ‚Ä¶  0.12669210665020722, 0.08544750291076005, 0.00995851250879033, 0.007968948212178776, -0.013797713811829282, 0.04089952358040575, 0.09843454434872823, 0.187754055643785, 0.12347714920224895, -0.02123223608402877],
 Œº = [-0.07425253786441717, 0.06260598855694459, 0.035656016260655655, 0.17147415210953537, 0.07818205464771197, 0.10772637696733235, 0.1907825647786839, 0.12137636804604132, -0.0340565694970403, 0.0902126436118248  ‚Ä¶  0.12669210665020722, 0.08544750291076005, 0.00995851250879033, 0.007968948212178776, -0.013797713811829282, 0.04089952358040575, 0.09843454434872823, 0.187754055643785, 0.12347714920224895, -0.02123223608402877],
 œÉ = 0.15317265159480417,
 Œ≤ = [-0.0314005201199959, 0.006786321917755004, 0.0020292142959154585, 0.10108788359235155],
 y = [0.11089985334870502, 0.24152656889653473, 0.1370343530870586, 0.25512625372397113, 0.017928081218942758, 0.2454735449010289, 0.14519505253082549, 0.32617330887820617, -0.18376058050162591, -0.02894713501836786  ‚Ä¶  0.03348888697588415, 0.05741769458237732, -0.12143841154415345, -0.03823589619320015, 0.012870099878921291, 0.14568060311729766, 0.19351117918517996, -0.09863549574312164, 0.13072699011422456, 0.20405215401857052],)</pre><p>Create an MLJ machine for fitting our model:</p><pre><code class="language-julia">mach = MLJBase.machine(model, X, truth.y)</code></pre><pre class="documenter-example-output">[34mMachine{SossMLJModel{Model{,‚Ä¶},‚Ä¶}} @991[39m trained 0 times.
  args: 
    1:	[34mSource @875[39m ‚èé `ScientificTypes.Table{Union{AbstractArray{ScientificTypes.Continuous,1}, AbstractArray{ScientificTypes.Count,1}}}`
    2:	[34mSource @093[39m ‚èé `AbstractArray{ScientificTypes.Continuous,1}`
</pre><p>Fit the machine. This may take several minutes.</p><pre><code class="language-julia">fit!(mach)</code></pre><pre class="documenter-example-output">[34mMachine{SossMLJModel{Model{,‚Ä¶},‚Ä¶}} @991[39m trained 1 time.
  args: 
    1:	[34mSource @875[39m ‚èé `ScientificTypes.Table{Union{AbstractArray{ScientificTypes.Continuous,1}, AbstractArray{ScientificTypes.Count,1}}}`
    2:	[34mSource @093[39m ‚èé `AbstractArray{ScientificTypes.Continuous,1}`
</pre><p>Construct the posterior distribution and the joint posterior predictive distribution:</p><pre><code class="language-julia">predictor_joint = predict_joint(mach, X)
typeof(predictor_joint)</code></pre><pre class="documenter-example-output">SossMLJ.SossMLJPredictor{SossMLJModel{Soss.Model{NamedTuple{(:X, :s, :t),T} where T&lt;:Tuple,TypeEncoding(begin
    œÉ ~ HalfNormal(t)
    p = size(X, 2)
    Œ≤ ~ Normal(0, s) |&gt; iid(p)
    Œ∑ = X * Œ≤
    Œº = Œ∑
    y ~ For(eachindex(Œº)) do j
            Normal(Œº[j], œÉ)
        end
end),TypeEncoding(Main.ex-example-linear-regression)},Main.ex-example-linear-regression.var&quot;#1#2&quot;,typeof(Soss.dynamicHMC),NamedTuple{(:s, :t),Tuple{Float64,Float64}},Symbol},Array{NamedTuple{(:œÉ, :Œ≤),Tuple{Float64,Array{Float64,1}}},1},Soss.Model{NamedTuple{(:X, :œÉ, :Œ≤),T} where T&lt;:Tuple,TypeEncoding(begin
    Œ∑ = X * Œ≤
    Œº = Œ∑
    y ~ For(eachindex(Œº)) do j
            Normal(Œº[j], œÉ)
        end
end),TypeEncoding(Main.ex-example-linear-regression)},NamedTuple{(:X, :s, :t),Tuple{Array{Float64,2},Float64,Float64}}}</pre><p>Draw a single sample from the joint posterior predictive distribution:</p><pre><code class="language-julia">single_sample = rand(predictor_joint; response = :y)</code></pre><pre class="documenter-example-output">100-element Array{Float64,1}:
 -0.10765949230220334
  0.16556399783486636
 -0.08685196972398287
  0.33537138168172387
  0.14844791919433337
  0.1637404922913596
  0.2570177112663715
  0.012949573266643713
  0.11993358500499805
 -0.013350224132792216
  ‚ãÆ
  0.4400780690565655
 -0.02563567981990534
  0.15527882066706505
  0.31097145327347514
 -0.03677875281482999
  0.04333168312327271
  0.29904851131973387
  0.07654051587486056
  0.05438802767430789</pre><p>Evaluate the logpdf of the joint posterior predictive distribution at this sample:</p><pre><code class="language-julia">logpdf(predictor_joint, single_sample)</code></pre><pre class="documenter-example-output">50.58928238735269</pre><p>True <code>Œ≤</code>:</p><pre><code class="language-julia">truth.Œ≤</code></pre><pre class="documenter-example-output">4-element Array{Float64,1}:
 -0.0314005201199959
  0.006786321917755004
  0.0020292142959154585
  0.10108788359235155</pre><p>Posterior distribution of <code>Œ≤</code></p><pre><code class="language-julia">predict_particles(mach, X; response = :Œ≤)</code></pre><pre class="documenter-example-output">4-element Array{MonteCarloMeasurements.Particles{Float64,1000},1}:
 -0.0118 ¬± 0.013
  0.0137 ¬± 0.013
 -0.0198 ¬± 0.023
  0.105 ¬± 0.021</pre><p>Difference between the posterior distribution of <code>Œ≤</code> to the true values:</p><pre><code class="language-julia">truth.Œ≤ - predict_particles(mach, X; response = :Œ≤)</code></pre><pre class="documenter-example-output">4-element Array{MonteCarloMeasurements.Particles{Float64,1000},1}:
 -0.0196 ¬± 0.013
 -0.00694 ¬± 0.013
  0.0218 ¬± 0.023
 -0.00371 ¬± 0.021</pre><p>Compare the joint posterior predictive distribution of <code>Œº</code> to the true values:</p><pre><code class="language-julia">truth.Œº - predict_particles(mach, X; response = :Œº)</code></pre><pre class="documenter-example-output">100-element Array{MonteCarloMeasurements.Particles{Float64,1000},1}:
 -0.0248 ¬± 0.036
  0.00634 ¬± 0.042
  0.00877 ¬± 0.019
  0.0512 ¬± 0.041
 -0.0146 ¬± 0.024
  0.00187 ¬± 0.022
  0.0347 ¬± 0.043
  0.00777 ¬± 0.023
 -0.00658 ¬± 0.029
  0.0298 ¬± 0.034
  ‚ãÆ
  0.00591 ¬± 0.025
  6.97e-5 ¬± 0.0075
  0.0404 ¬± 0.029
 -0.00404 ¬± 0.007
 -0.0364 ¬± 0.034
 -0.000588 ¬± 0.023
  0.0734 ¬± 0.043
  0.0335 ¬± 0.039
  0.00119 ¬± 0.026</pre><p>Compare the joint posterior predictive distribution of <code>y</code> to the true values:</p><pre><code class="language-julia">truth.y - predict_particles(mach, X; response = :y)</code></pre><pre class="documenter-example-output">100-element Array{MonteCarloMeasurements.Particles{Float64,1000},1}:
  0.161 ¬± 0.15
  0.185 ¬± 0.15
  0.111 ¬± 0.14
  0.135 ¬± 0.15
 -0.0747 ¬± 0.14
  0.139 ¬± 0.14
 -0.0106 ¬± 0.15
  0.212 ¬± 0.14
 -0.156 ¬± 0.14
 -0.0902 ¬± 0.15
  ‚ãÆ
 -0.0219 ¬± 0.14
 -0.131 ¬± 0.14
 -0.0064 ¬± 0.14
  0.0223 ¬± 0.14
  0.068 ¬± 0.14
  0.0943 ¬± 0.14
 -0.213 ¬± 0.15
  0.0407 ¬± 0.15
  0.227 ¬± 0.14</pre><p>Construct each of the marginal posterior predictive distributions:</p><pre><code class="language-julia">predictor_marginal = MLJBase.predict(mach, X)
typeof(predictor_marginal)</code></pre><pre class="documenter-example-output">Array{SossMLJ.SossMLJPredictor{SossMLJModel{Soss.Model{NamedTuple{(:X, :s, :t),T} where T&lt;:Tuple,TypeEncoding(begin
    œÉ ~ HalfNormal(t)
    p = size(X, 2)
    Œ≤ ~ Normal(0, s) |&gt; iid(p)
    Œ∑ = X * Œ≤
    Œº = Œ∑
    y ~ For(eachindex(Œº)) do j
            Normal(Œº[j], œÉ)
        end
end),TypeEncoding(Main.ex-example-linear-regression)},Main.ex-example-linear-regression.var&quot;#1#2&quot;,typeof(Soss.dynamicHMC),NamedTuple{(:s, :t),Tuple{Float64,Float64}},Symbol},Array{NamedTuple{(:œÉ, :Œ≤),Tuple{Float64,Array{Float64,1}}},1},Soss.Model{NamedTuple{(:X, :œÉ, :Œ≤),T} where T&lt;:Tuple,TypeEncoding(begin
    Œ∑ = X * Œ≤
    Œº = Œ∑
    y ~ For(eachindex(Œº)) do j
            Normal(Œº[j], œÉ)
        end
end),TypeEncoding(Main.ex-example-linear-regression)},NamedTuple{(:X, :s, :t),Tuple{Array{Float64,2},Float64,Float64}}},1}</pre><p><code>predictor_marginal</code> has one element for each row in <code>X</code></p><pre><code class="language-julia">size(predictor_marginal)</code></pre><pre class="documenter-example-output">(100,)</pre><p>Draw a single sample from each of the marginal posterior predictive distributions:</p><pre><code class="language-julia">only.(rand.(predictor_marginal))</code></pre><pre class="documenter-example-output">100-element Array{Float64,1}:
  0.02604621723665456
  0.1165815956130386
  0.044638490667916426
 -0.10949826769286392
 -0.11977586105032227
 -0.005115780041207815
  0.27347962063913867
  0.11908127112929805
  0.09419466265053043
  0.045100575523964
  ‚ãÆ
  0.05372553741014695
 -0.11085116704576642
  0.2853588853317399
  0.1440815540645027
 -0.061284436439523624
  0.2945356373102784
  0.3770324376509444
 -0.17736466797280181
 -0.011607504524911915</pre><p>Use cross-validation to evaluate the model with respect to the expected value of the root mean square error (RMSE)</p><pre><code class="language-julia">evaluate!(mach, resampling=CV(), measure=rms_expected, operation=predict_particles)</code></pre><pre class="documenter-example-output">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ _.measure   ‚îÇ _.measurement ‚îÇ _.per_fold                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ RMSExpected ‚îÇ 0.199         ‚îÇ [0.207, 0.2, 0.211, 0.204, 0.174, 0.198] ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
_.per_observation = [missing]
</pre><p>Use cross-validation to evaluate the model with respect to the median of the root mean square error (RMSE)</p><pre><code class="language-julia">evaluate!(mach, resampling=CV(), measure=rms_median, operation=predict_particles)</code></pre><pre class="documenter-example-output">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ _.measure ‚îÇ _.measurement ‚îÇ _.per_fold                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ RMSMedian ‚îÇ 0.198         ‚îÇ [0.205, 0.2, 0.211, 0.204, 0.171, 0.197] ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
_.per_observation = [missing]
</pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">¬´ Home</a><a class="docs-footer-nextpage" href="../example-multinomial-logistic-regression/">Multinomial logistic regression ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 27 August 2020 00:11">Thursday 27 August 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
